# =============================================================================
# TimescaleDB Configuration for BIST Trading Platform
# Optimized for high-frequency market data ingestion and queries
# =============================================================================

# =============================================================================
# CONNECTION AND AUTHENTICATION
# =============================================================================
listen_addresses = '*'
port = 5432
max_connections = 200
superuser_reserved_connections = 3

# =============================================================================
# MEMORY CONFIGURATION (Optimized for time-series workloads)
# =============================================================================
# For 6GB container (adjust based on available memory)
shared_buffers = 1536MB                    # 25% of available memory
effective_cache_size = 4608MB              # 75% of available memory
work_mem = 64MB                            # For complex time-series queries
maintenance_work_mem = 512MB               # For index creation and maintenance
autovacuum_work_mem = 256MB               # For auto-vacuum processes

# Temporary file handling
temp_buffers = 32MB
temp_file_limit = 10GB

# =============================================================================
# TIMESCALEDB SPECIFIC SETTINGS
# =============================================================================
# Enable TimescaleDB extension
shared_preload_libraries = 'timescaledb,pg_stat_statements'

# TimescaleDB chunk settings
timescaledb.max_background_workers = 8
timescaledb.last_updated_threshold = '1min'

# Compression settings for TimescaleDB
timescaledb.compress_segmentby_default = 'true'
timescaledb.compress_orderby_default = 'time DESC'

# =============================================================================
# WAL (Write-Ahead Logging) - Optimized for high write throughput
# =============================================================================
wal_level = replica                        # Enable replication
wal_log_hints = on                         # For pg_rewind support
fsync = on                                 # Ensure data durability
synchronous_commit = off                   # Async commit for performance
wal_sync_method = fdatasync               # Fastest sync method on Linux

# WAL file management
max_wal_size = 8GB                        # Large WAL for high write volume
min_wal_size = 2GB                        # Minimum WAL size
wal_buffers = 64MB                        # WAL buffer size
wal_writer_delay = 10ms                   # More frequent WAL writes

# Archiving (for backup and replication)
archive_mode = on
archive_command = 'cp %p /var/lib/postgresql/wal_archive/%f'
archive_timeout = 300                     # Archive every 5 minutes

# =============================================================================
# REPLICATION SETTINGS
# =============================================================================
max_wal_senders = 10                      # Maximum replication connections
max_replication_slots = 10                # Replication slot limit
hot_standby = on                          # Read queries on standby
hot_standby_feedback = on                 # Prevent query conflicts

# =============================================================================
# QUERY PLANNER (Optimized for time-series queries)
# =============================================================================
random_page_cost = 1.1                   # SSD optimized
seq_page_cost = 1.0                      # Sequential scan cost
cpu_tuple_cost = 0.01                    # CPU cost per tuple
cpu_index_tuple_cost = 0.005             # CPU cost per index tuple
cpu_operator_cost = 0.0025               # CPU cost per operator

# Join settings for large time-series joins
enable_hashjoin = on
enable_mergejoin = on
enable_nestloop = off                     # Disable nested loops for large datasets

# =============================================================================
# BACKGROUND PROCESSES
# =============================================================================
# Background writer (for steady I/O)
bgwriter_delay = 50ms                     # More frequent writes
bgwriter_lru_maxpages = 500              # Pages written per round
bgwriter_lru_multiplier = 10.0           # Aggressive background writing
bgwriter_flush_after = 512kB             # Flush OS cache

# Autovacuum (Critical for time-series data)
autovacuum = on
autovacuum_max_workers = 6               # More workers for large tables
autovacuum_naptime = 15s                 # More frequent autovacuum
autovacuum_vacuum_threshold = 50         # Minimum updates for vacuum
autovacuum_vacuum_scale_factor = 0.05    # 5% of table size
autovacuum_analyze_threshold = 50        # Minimum updates for analyze
autovacuum_analyze_scale_factor = 0.02   # 2% of table size for analyze

# Vacuum cost settings (prevent vacuum from overwhelming I/O)
vacuum_cost_delay = 2ms
vacuum_cost_page_hit = 1
vacuum_cost_page_miss = 10
vacuum_cost_page_dirty = 20
vacuum_cost_limit = 2000

# =============================================================================
# CHECKPOINTS (Optimized for write-heavy workload)
# =============================================================================
checkpoint_completion_target = 0.9       # Spread checkpoints over 90% of interval
checkpoint_timeout = 15min               # Checkpoint every 15 minutes
checkpoint_warning = 300s                # Warn if checkpoints are too frequent
checkpoint_flush_after = 256kB          # Flush pages to OS

# =============================================================================
# PARALLEL QUERY PROCESSING
# =============================================================================
max_worker_processes = 8                 # Maximum background processes
max_parallel_workers = 6                # Maximum parallel workers
max_parallel_workers_per_gather = 4     # Max workers per gather node
min_parallel_table_scan_size = 8MB      # Minimum table size for parallel scan
min_parallel_index_scan_size = 512kB    # Minimum index size for parallel scan

# =============================================================================
# LOGGING (Comprehensive for financial compliance)
# =============================================================================
log_destination = 'stderr,csvlog'        # Multiple log formats
logging_collector = on                   # Enable log collection
log_directory = '/var/log/postgresql'    # Log directory
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_file_mode = 0640                     # Log file permissions
log_rotation_age = 1d                    # Daily log rotation
log_rotation_size = 100MB                # Size-based rotation
log_truncate_on_rotation = on            # Truncate old logs

# What to log
log_min_messages = warning               # Log warnings and above
log_min_error_statement = error          # Log error statements
log_min_duration_statement = 100ms      # Log slow queries (100ms+)
log_checkpoints = on                     # Log checkpoint info
log_connections = on                     # Log connections
log_disconnections = on                  # Log disconnections
log_lock_waits = on                      # Log lock waits
log_temp_files = 10MB                    # Log large temp files
log_autovacuum_min_duration = 250ms     # Log slow autovacuum

# Statement logging
log_statement = 'mod'                    # Log modifications only
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# =============================================================================
# STATISTICS AND MONITORING
# =============================================================================
track_activities = on                    # Track active queries
track_counts = on                        # Track table/index usage
track_io_timing = on                     # Track I/O timing
track_functions = all                    # Track function calls

# pg_stat_statements configuration
pg_stat_statements.max = 10000          # Track more statements
pg_stat_statements.track = all          # Track all statements
pg_stat_statements.track_utility = on   # Track utility commands
pg_stat_statements.save = on            # Persist across restarts

# =============================================================================
# LOCK MANAGEMENT (Important for high-concurrency trading)
# =============================================================================
deadlock_timeout = 1s                   # Deadlock detection timeout
max_locks_per_transaction = 512         # Increased lock table size
max_pred_locks_per_transaction = 512    # Serializable isolation locks

# =============================================================================
# STORAGE AND I/O SETTINGS
# =============================================================================
effective_io_concurrency = 200          # SSD concurrent I/O operations
maintenance_io_concurrency = 10         # Maintenance I/O concurrency

# Asynchronous I/O
wal_sync_method = fdatasync             # Fastest sync method
full_page_writes = off                   # Disable for better performance (ensure filesystem reliability)

# =============================================================================
# TIME ZONE AND LOCALE
# =============================================================================
timezone = 'Europe/Istanbul'            # Turkish timezone for BIST
log_timezone = 'Europe/Istanbul'        # Log timezone
lc_messages = 'en_US.UTF-8'            # Message language
lc_monetary = 'tr_TR.UTF-8'            # Turkish monetary format
lc_numeric = 'en_US.UTF-8'             # Numeric format
lc_time = 'tr_TR.UTF-8'                # Turkish time format

# =============================================================================
# EXTENSIONS AND FEATURES
# =============================================================================
# Additional extensions for time-series analysis
shared_preload_libraries = 'timescaledb,pg_stat_statements,pg_cron'

# Enable JIT compilation for complex queries
jit = on
jit_above_cost = 100000
jit_inline_above_cost = 500000
jit_optimize_above_cost = 500000

# =============================================================================
# CUSTOM SETTINGS FOR FINANCIAL DATA
# =============================================================================
# Increase identifier length for financial instruments
max_identifier_length = 128

# Increase numeric precision for financial calculations
extra_float_digits = 3

# Custom GUC variables for application
# bist_trading.market_open_time = '10:00'
# bist_trading.market_close_time = '18:00'
# bist_trading.trading_enabled = 'true'

# =============================================================================
# PERFORMANCE MONITORING QUERIES
# =============================================================================
# These settings help with performance analysis:
# - pg_stat_statements for query performance
# - track_io_timing for I/O analysis
# - log_min_duration_statement for slow query identification
# - Various track_* settings for resource usage monitoring

# =============================================================================
# SECURITY CONSIDERATIONS
# =============================================================================
# SSL settings (configure SSL certificates separately)
ssl = off                               # Enable SSL/TLS (configure certificates)
# ssl_cert_file = 'server.crt'
# ssl_key_file = 'server.key'
# ssl_ciphers = 'ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256'

# Password encryption
password_encryption = scram-sha-256     # Strong password hashing

# Row security
row_security = on                       # Enable row-level security

# =============================================================================
# NOTES FOR OPTIMIZATION
# =============================================================================
# 1. Monitor pg_stat_statements for query optimization opportunities
# 2. Use EXPLAIN (ANALYZE, BUFFERS) for query analysis
# 3. Monitor autovacuum activity and adjust settings as needed
# 4. Consider partitioning large hypertables for better performance
# 5. Use appropriate compression settings for older data
# 6. Monitor checkpoint frequency and adjust if too frequent
# 7. Regularly analyze table statistics for optimal query plans